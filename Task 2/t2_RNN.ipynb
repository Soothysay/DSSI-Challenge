{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 RNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "- [ECG Heartbeat Classification: A Deep Transferable Representation](https://arxiv.org/pdf/1805.00794.pdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 10:00:36.582292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIT-BIH  Arrhythmia Dataset\n",
    "\n",
    "- Number of Samples: 109446\n",
    "- Number of Categories: 5\n",
    "- Sampling Frequency: 125Hz\n",
    "- Data Source: Physionet's MIT-BIH Arrhythmia Dataset\n",
    "- Classes: ['N': 0, 'S': 1, 'V': 2, 'F': 3, 'Q': 4]\n",
    "- Remark: All the samples are cropped, downsampled and padded with zeroes if necessary to the fixed dimension of 188.\n",
    "- The final element of each row denotes the class to which that example belongs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the mitbih_train is :  (87554, 188)\n",
      "The shape of the mitbih_test is :  (21892, 188)\n"
     ]
    }
   ],
   "source": [
    "df_mitbih_train = pd.read_csv(\"../ecg_dataset/mitbih_train.csv\", header = None)\n",
    "df_mitbih_test = pd.read_csv(\"../ecg_dataset/mitbih_test.csv\", header = None)\n",
    "\n",
    "# print shapes of the dataframes\n",
    "print(\"The shape of the mitbih_train is : \", df_mitbih_train.shape)\n",
    "print(\"The shape of the mitbih_test is : \", df_mitbih_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model for classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_mitbih_train.iloc[: , :-1], df_mitbih_train.iloc[: , -1]\n",
    "\n",
    "X_test, y_test = df_mitbih_test.iloc[:,:-1], df_mitbih_test.iloc[: , -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 187)]             0         \n",
      "                                                                 \n",
      " tf.expand_dims_7 (TFOpLambd  (None, 187, 1)           0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 187, 256)          198912    \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 47872)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 239365    \n",
      "                                                                 \n",
      " tf.math.argmax_2 (TFOpLambd  (5,)                     0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (5,)                      0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 438,277\n",
      "Trainable params: 438,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "expand = tf.expand_dims(inputs, axis=2)\n",
    "gru = tf.keras.layers.GRU(256, return_sequences=True)(expand)\n",
    "flatten = tf.keras.layers.Flatten()(gru)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(5, activation='softmax')(flatten)\n",
    "outputs1=tf.math.argmax(outputs)\n",
    "outputs1=tf.cast(outputs1,tf.int32)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs1)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 1992, in categorical_crossentropy\n        label_smoothing = tf.convert_to_tensor(label_smoothing, dtype=y_pred.dtype)\n\n    TypeError: Expected int32, but got 0.0 of type 'float'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m      2\u001b[0m     optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m                        tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mPrecision(), tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mRecall()]\n\u001b[1;32m      6\u001b[0m                        )\n\u001b[0;32m----> 8\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      9\u001b[0m     X_train,\n\u001b[1;32m     10\u001b[0m     labels,\n\u001b[1;32m     11\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     15\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(\n\u001b[1;32m     16\u001b[0m             monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m             patience\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m             restore_best_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m         )\n\u001b[1;32m     20\u001b[0m     ]\n\u001b[1;32m     21\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/2m/w0zz6d990yq1vg32d2h6xyd4001xvw/T/__autograph_generated_filen1k4527f.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/bender13/anaconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 1992, in categorical_crossentropy\n        label_smoothing = tf.convert_to_tensor(label_smoothing, dtype=y_pred.dtype)\n\n    TypeError: Expected int32, but got 0.0 of type 'float'.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', \n",
    "                       tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "                       )\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    labels,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
