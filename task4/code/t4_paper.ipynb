{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset from the [Dataset of Simulated Intracardiac Transmembrane Voltage Recordings and ECG Signals](https://library.ucsd.edu/dc/object/bb29449106) using the script `download_intracardiac_dataset.sh`:\n",
    "\n",
    "```bash\n",
    "source download_intracardiac_dataset.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules and Preprocessing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load modules and preprocessing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import tensorflow as tf \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `cardiac_ml_tools` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run cardiac_ml_tools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of file pairs: 16117\n",
      "Example of file pair:\n",
      "../intracardiac_dataset/data_hearts_dd_0p2/pECGData_hearts_dd_0p2_volunteer.v10_pattern.0.npy\n",
      "../intracardiac_dataset/data_hearts_dd_0p2/VmData_hearts_dd_0p2_volunteer.v10_pattern.0.npy\n"
     ]
    }
   ],
   "source": [
    "data_dirs = []\n",
    "regex = r'data_hearts_dd_0p2*'\n",
    "DIR='../intracardiac_dataset/' # This should be the path to the intracardiac_dataset, it can be downloaded using data_science_challenge_2023/download_intracardiac_dataset.sh\n",
    "for x in os.listdir(DIR):\n",
    "    if re.match(regex, x):\n",
    "        data_dirs.append(DIR + x)\n",
    "file_pairs = read_data_dirs(data_dirs)\n",
    "print('Number of file pairs: {}'.format(len(file_pairs)))\n",
    "# example of file pair\n",
    "print(\"Example of file pair:\")\n",
    "print(\"{}\\n{}\".format(file_pairs[0][0], file_pairs[0][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the article: \"each V was normalized so that the value range was [0,1].\" I'm interpreting 'value range' as the values in the \"Getting transmembrane voltages\" plot. I'm also assuming that for each case we'll normalize all of the 75 components at once. \n",
    "\n",
    "So we run through every case (16,117 total cases), subtract the minimum V value (to make smallest value = 0), then divide the resulting data by its maximum (to make range = [0,1]). Which means at least 75*500*16117*2 = 1.2e9 flops. Note this doesn't include the cost of loading each dataset nor the cost of loading ECG data and performing the standard_leads mapping. With operations of this scale it'll be important that we use any HPC resources we have. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.6536614894867\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "# Create an empty list to hold ECG and V matrices\n",
    "ECG_list = [] \n",
    "V_list = []\n",
    "\n",
    "# Loop over the cases and load the matrices\n",
    "for case in range(len(file_pairs)):\n",
    "    ## ECG \n",
    "    ECG = np.load(file_pairs[case][0])\n",
    "    \n",
    "    # Map from 10 leads to 12 \n",
    "    ECG = get_standard_leads(ECG)\n",
    "    \n",
    "    # Normalize ECG so that the minimum and maximum for each col are separated by a distance of 1\n",
    "    ECG = (ECG - ECG.min(axis=0))/(ECG.max(axis=0) - ECG.min(axis=0))\n",
    "\n",
    "    # Append to ECG list \n",
    "    ECG_list.append(ECG)\n",
    "    \n",
    "    \n",
    "    ## V\n",
    "    V = np.load(file_pairs[case][1])\n",
    "\n",
    "    # Normalize V so that \"value range is [0,1]\"\n",
    "    V = V - np.min(V)\n",
    "    V = V/np.max(V)\n",
    "\n",
    "    # Append the normalized V matrix to the list \n",
    "    V_list.append(V)\n",
    "\n",
    "# Reshape into tensor for dimension agreement\n",
    "ECGtens = np.array(ECG_list)\n",
    "Vtens = np.array(V_list)\n",
    "\n",
    "\n",
    "toc = time.time()\n",
    "print(f\"time to normalize/load = {toc-tic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "(500, 12)\n",
      "(500, 75)\n"
     ]
    }
   ],
   "source": [
    "print(ECGtens[1,:,:].max(axis=0)-ECGtens[1,:,:].min(axis=0)) #proof that dist between max and min equals one \n",
    "print(ECGtens[1,:,:].shape) #Note that the ECG data is 500 by 12 -- not the other way around (as the paper describes)\n",
    "print(Vtens[1,:,:].shape) #Similarly, 500 by 75, not 75 by 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, XX, y, yy = train_test_split(ECGtens, Vtens, test_size=0.05, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the training set small for debugging\n",
    "Xsmall, XXsmall, ysmall, yysmall = train_test_split(ECGtens[:4], Vtens[:4], \n",
    "                                                    test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code for the squeezenet model as its described in the powerpoint slide. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FireModule(tf.keras.layers.Layer):\n",
    "#     def __init__(self, squeeze_channels, expand_channels):\n",
    "#         super(FireModule, self).__init__()\n",
    "#         self.squeeze = tf.keras.layers.Conv1D(squeeze_channels, 1, activation='relu')\n",
    "#         self.expand1x1 = tf.keras.layers.Conv1D(expand_channels, 1, activation='relu')\n",
    "#         self.expand3x3 = tf.keras.layers.Conv1D(expand_channels, 3, padding='same', activation='relu')\n",
    "\n",
    "#     def call(self, x):\n",
    "#         squeeze = self.squeeze(x)\n",
    "#         expand1x1 = self.expand1x1(squeeze)\n",
    "#         expand3x3 = self.expand3x3(squeeze)\n",
    "#         return tf.concat([expand1x1, expand3x3], axis=0)\n",
    "\n",
    "# # Define your model\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Input(shape=(500,12)),\n",
    "#     tf.keras.layers.Conv1D(64, 3, strides=1, padding='same'),\n",
    "#     tf.keras.layers.MaxPool1D(3, strides=1, padding='same'),\n",
    "#     FireModule(16, 64),\n",
    "#     FireModule(16, 64),\n",
    "#     tf.keras.layers.MaxPool1D(3, strides=1, padding='same'),\n",
    "#     FireModule(32, 128),\n",
    "#     FireModule(32, 128),\n",
    "#     tf.keras.layers.MaxPool1D(3, strides=1, padding='same'),\n",
    "#     FireModule(48, 192),\n",
    "#     FireModule(48, 192),\n",
    "#     FireModule(64, 256),\n",
    "#     FireModule(64, 256),\n",
    "#     tf.keras.layers.Dropout(0.1),\n",
    "#     tf.keras.layers.Conv1D(75, 1, padding='valid'),\n",
    "#     tf.keras.layers.ReLU()\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't actually run so I've commented it out. To make dimensions line up, I've added extra convolutional layers at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, squeeze_channels, expand_channels):\n",
    "        super(FireModule, self).__init__()\n",
    "        self.squeeze = tf.keras.layers.Conv1D(squeeze_channels, 1, activation='relu')\n",
    "        self.expand1x1 = tf.keras.layers.Conv1D(expand_channels, 1, activation='relu')\n",
    "        self.expand3x3 = tf.keras.layers.Conv1D(expand_channels, 3, padding='same', activation='relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        squeeze = self.squeeze(x)\n",
    "        expand1x1 = self.expand1x1(squeeze)\n",
    "        expand3x3 = self.expand3x3(squeeze)\n",
    "        return tf.concat([expand1x1, expand3x3], axis=1)\n",
    "\n",
    "# Define your model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(500,12)),\n",
    "\n",
    "    tf.keras.layers.Conv1D(64, 3, strides=1, padding='same'),\n",
    "\n",
    "    tf.keras.layers.MaxPool1D(3, strides=2, padding='same'),\n",
    "\n",
    "    FireModule(16, 64),\n",
    "    FireModule(16, 64), \n",
    "\n",
    "    tf.keras.layers.MaxPool1D(3, strides=2, padding='same'),\n",
    "\n",
    "    FireModule(32, 128),\n",
    "    FireModule(32, 128),\n",
    "\n",
    "    tf.keras.layers.MaxPool1D(3, strides=2, padding='same'),\n",
    "\n",
    "    FireModule(48, 192),\n",
    "    FireModule(48, 192),\n",
    "    FireModule(64, 256),\n",
    "    FireModule(64, 256),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "\n",
    "    tf.keras.layers.Conv1D(75, 1, strides=1),\n",
    "\n",
    "    tf.keras.layers.AvgPool1D(),\n",
    "\n",
    "    tf.keras.layers.Conv1D(75, 3, strides=2,padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv1D(75, 3, strides=2,padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv1D(75, 3, strides=2,padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv1D(75, 3, strides=2,padding='same'),\n",
    "    tf.keras.layers.ReLU()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.MeanSquaredError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to notice is that my model isn't an exact replica of what they have in the paper. In the paper they mention that their model has 392,907 paramters while mine has 390,307:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 500, 64)           2368      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 250, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " fire_module (FireModule)    (None, 500, 64)           5264      \n",
      "                                                                 \n",
      " fire_module_1 (FireModule)  (None, 1000, 64)          5264      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 500, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " fire_module_2 (FireModule)  (None, 1000, 128)         18720     \n",
      "                                                                 \n",
      " fire_module_3 (FireModule)  (None, 2000, 128)         20768     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 1000, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " fire_module_4 (FireModule)  (None, 2000, 192)         43440     \n",
      "                                                                 \n",
      " fire_module_5 (FireModule)  (None, 4000, 192)         46512     \n",
      "                                                                 \n",
      " fire_module_6 (FireModule)  (None, 8000, 256)         78400     \n",
      "                                                                 \n",
      " fire_module_7 (FireModule)  (None, 16000, 256)        82496     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16000, 256)        0         \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 16000, 75)         19275     \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 8000, 75)         0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " conv1d_26 (Conv1D)          (None, 4000, 75)          16950     \n",
      "                                                                 \n",
      " conv1d_27 (Conv1D)          (None, 2000, 75)          16950     \n",
      "                                                                 \n",
      " conv1d_28 (Conv1D)          (None, 1000, 75)          16950     \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 500, 75)           16950     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 500, 75)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 390,307\n",
      "Trainable params: 390,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure there are no errors, let's run the model on a tiny subset of our total data. This should run pretty quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4165 - mean_squared_error: 0.4165\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.4090 - mean_squared_error: 0.4090\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3930 - mean_squared_error: 0.3930\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.3607 - mean_squared_error: 0.3607\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.3026 - mean_squared_error: 0.3026\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.2332 - mean_squared_error: 0.2332\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.2853 - mean_squared_error: 0.2853\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1774 - mean_squared_error: 0.1774\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1603 - mean_squared_error: 0.1603\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1634 - mean_squared_error: 0.1634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aae33c0cb50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xsmall, ysmall, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the real thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "479/479 [==============================] - 1105s 2s/step - loss: 0.0444 - mean_squared_error: 0.0444\n",
      "Epoch 2/30\n",
      "479/479 [==============================] - 1105s 2s/step - loss: 0.0317 - mean_squared_error: 0.0317\n",
      "Epoch 3/30\n",
      "479/479 [==============================] - 1104s 2s/step - loss: 0.0290 - mean_squared_error: 0.0290\n",
      "Epoch 4/30\n",
      "479/479 [==============================] - 1090s 2s/step - loss: 0.0250 - mean_squared_error: 0.0250\n",
      "Epoch 5/30\n",
      "479/479 [==============================] - 1092s 2s/step - loss: 0.0218 - mean_squared_error: 0.0218\n",
      "Epoch 6/30\n",
      "479/479 [==============================] - 1075s 2s/step - loss: 0.0202 - mean_squared_error: 0.0202\n",
      "Epoch 7/30\n",
      "479/479 [==============================] - 1058s 2s/step - loss: 0.0194 - mean_squared_error: 0.0194\n",
      "Epoch 8/30\n",
      "479/479 [==============================] - 1066s 2s/step - loss: 0.0189 - mean_squared_error: 0.0189\n",
      "Epoch 9/30\n",
      "479/479 [==============================] - 1068s 2s/step - loss: 0.0185 - mean_squared_error: 0.0185\n",
      "Epoch 10/30\n",
      "479/479 [==============================] - 1101s 2s/step - loss: 0.0182 - mean_squared_error: 0.0182\n",
      "Epoch 11/30\n",
      "479/479 [==============================] - 1123s 2s/step - loss: 0.0179 - mean_squared_error: 0.0179\n",
      "Epoch 12/30\n",
      "479/479 [==============================] - 1076s 2s/step - loss: 0.0176 - mean_squared_error: 0.0176\n",
      "Epoch 13/30\n",
      "479/479 [==============================] - 1075s 2s/step - loss: 0.0174 - mean_squared_error: 0.0174\n",
      "Epoch 14/30\n",
      "479/479 [==============================] - 1066s 2s/step - loss: 0.0173 - mean_squared_error: 0.0173\n",
      "Epoch 15/30\n",
      "479/479 [==============================] - 1068s 2s/step - loss: 0.0170 - mean_squared_error: 0.0170\n",
      "Epoch 16/30\n",
      "479/479 [==============================] - 1109s 2s/step - loss: 0.0169 - mean_squared_error: 0.0169\n",
      "Epoch 17/30\n",
      "479/479 [==============================] - 1112s 2s/step - loss: 0.0168 - mean_squared_error: 0.0168\n",
      "Epoch 18/30\n",
      "479/479 [==============================] - 1101s 2s/step - loss: 0.0166 - mean_squared_error: 0.0166\n",
      "Epoch 19/30\n",
      "479/479 [==============================] - 1089s 2s/step - loss: 0.0165 - mean_squared_error: 0.0165\n",
      "Epoch 20/30\n",
      "479/479 [==============================] - 1118s 2s/step - loss: 0.0164 - mean_squared_error: 0.0164\n",
      "Epoch 21/30\n",
      "479/479 [==============================] - 1114s 2s/step - loss: 0.0162 - mean_squared_error: 0.0162\n",
      "Epoch 22/30\n",
      "479/479 [==============================] - 1105s 2s/step - loss: 0.0161 - mean_squared_error: 0.0161\n",
      "Epoch 23/30\n",
      "479/479 [==============================] - 1105s 2s/step - loss: 0.0160 - mean_squared_error: 0.0160\n",
      "Epoch 24/30\n",
      "435/479 [==========================>...] - ETA: 1:41 - loss: 0.0159 - mean_squared_error: 0.0159"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how the model did. First, let's create our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(XX)\n",
    "print(ypred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results for a random prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-69bbfbcab068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m806\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# plot in row the tensors pECGData and ActTime with an arrow pointing to the activation time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "num = np.random.randint(1,806)\n",
    "true = yy[num,:,:]\n",
    "pred = ypred[num,:,:]\n",
    "\n",
    "# plot in row the tensors pECGData and ActTime with an arrow pointing to the activation time\n",
    "row = 1\n",
    "column = 3\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(row, column, 1)\n",
    "# plot pECGData transposed\n",
    "plt.imshow(true.T, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "plt.title('True data')\n",
    "plt.subplot(row, column, 2)\n",
    "# print a text \"->\"\n",
    "plt.text(0.5, 0.5, 'Vs', fontsize=40, horizontalalignment='center', verticalalignment='center')\n",
    "plt.axis('off')\n",
    "plt.subplot(row, column, 3)\n",
    "# plot Vm transposed\n",
    "plt.imshow(pred.T, cmap='jet', interpolation='nearest', aspect='auto')\n",
    "# not xticks\n",
    "plt.xticks([])\n",
    "plt.title('Reconstructed data')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider the MSE between the true and predicted data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 14s 506ms/step - loss: 0.0177 - mean_squared_error: 0.0177\n",
      "[0.01770629920065403, 0.01770629733800888]\n"
     ]
    }
   ],
   "source": [
    "mse = model.evaluate(XX,yy)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's consider the average activation times... Which I think is what Mikel is doing...(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_time_metric(true_data, predicted_data):\n",
    "    case_metrics = []\n",
    "    \n",
    "    for true_case, predicted_case in zip(true_data, predicted_data):\n",
    "        true_argmax = np.argmax(true_case, axis=0)\n",
    "        predicted_argmax = np.argmax(predicted_case, axis=0)\n",
    "        abs_diff = np.abs(true_argmax - predicted_argmax)\n",
    "        case_metric = np.mean(abs_diff) #, np.var(abs_diff)\n",
    "        case_metrics.append(case_metric)\n",
    "    \n",
    "    avg_metrics = np.mean(case_metrics, axis=0)\n",
    "    var_metrics = np.var(case_metrics, axis=0)\n",
    "    \n",
    "    return avg_metrics, var_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Time Average: 37.00251447477254\n",
      "Activation Time Variance: 76.85077548055972\n"
     ]
    }
   ],
   "source": [
    "avg, var = activation_time_metric(yy,ypred)\n",
    "print(\"Activation Time Average:\", avg)\n",
    "print(\"Activation Time Variance:\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which are far from Mikel's results... \n",
    "\n",
    "There's still work to be done on this model. If someone wants to pick up from where I left off, below I provide some code that helps with debugging/playing around: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############  # #FOR TESTING\n",
    "\n",
    "# class FireModule(tf.keras.layers.Layer):\n",
    "#     def __init__(self, squeeze_channels, expand_channels):\n",
    "#         super(FireModule, self).__init__()\n",
    "#         self.squeeze = tf.keras.layers.Conv1D(squeeze_channels, 1, activation='relu')\n",
    "#         self.expand1x1 = tf.keras.layers.Conv1D(expand_channels, 1, activation='relu')\n",
    "#         self.expand3x3 = tf.keras.layers.Conv1D(expand_channels, 3, padding='same', activation='relu')\n",
    "\n",
    "#     def call(self, x):\n",
    "#         # tf.print('Input shape:', x.shape)\n",
    "#         squeeze = self.squeeze(x)\n",
    "#         expand1x1 = self.expand1x1(squeeze)\n",
    "#         expand3x3 = self.expand3x3(squeeze)\n",
    "#         # tf.print('Output shape:', x.shape)\n",
    "#         return tf.concat([expand1x1, expand3x3], axis=1)\n",
    "    \n",
    "# class PrintMod(tf.keras.layers.Layer):\n",
    "#     def __init__(self, message=''):\n",
    "#         super(PrintMod, self).__init__()\n",
    "#         self.message = message\n",
    "\n",
    "#     def call(self, x):\n",
    "#         tf.print(self.message, 'shape:', x.shape)\n",
    "#         return x\n",
    "\n",
    "# # # Define your model\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Input(shape=(500,12)),\n",
    "#     # tf.keras.layers.Input(shape=(12,500)),\n",
    "#     PrintMod('After input'),\n",
    "\n",
    "#     tf.keras.layers.Conv1D(64, 3, strides=1, padding='same'),\n",
    "#     # tf.keras.layers.Conv1D(64, 3, strides=2, padding='same'), #output is 12 by 250\n",
    "#     PrintMod('After Conv1D(64, 3, strides=2, padding=same)'),\n",
    "\n",
    "#     # tf.keras.layers.MaxPool1D(3, strides=1, padding='same'),\n",
    "#     tf.keras.layers.MaxPool1D(3, strides=2, padding='same'), #output is 12 by 125\n",
    "#     PrintMod('After MaxPool1D(3, strides=2, padding=same)'),\n",
    "\n",
    "#     FireModule(16, 64), #output is 64 by 250 (I think)\n",
    "#     PrintMod('After Fire 16, 64'),\n",
    "#     FireModule(16, 64), \n",
    "#     PrintMod('After Fire 16, 64'),\n",
    "\n",
    "#     # tf.keras.layers.MaxPool1D(3, strides=1, padding='same'),\n",
    "#     tf.keras.layers.MaxPool1D(3, strides=2, padding='same'),\n",
    "#     PrintMod('After MaxPool1D(3, strides=2, padding=same)'),\n",
    "\n",
    "#     FireModule(32, 128),\n",
    "#     PrintMod('After fire 32, 128'),\n",
    "#     FireModule(32, 128),\n",
    "#     PrintMod('After fire 32, 128'),\n",
    "\n",
    "\n",
    "#     # tf.keras.layers.MaxPool1D(3, strides=1, padding='same'),\n",
    "#     tf.keras.layers.MaxPool1D(3, strides=2, padding='same'),\n",
    "#     PrintMod('After MaxPool1D(3, strides=2, padding=same)'),\n",
    "\n",
    "#     FireModule(48, 192),\n",
    "#     PrintMod('After fire 48, 192'),\n",
    "#     FireModule(48, 192),\n",
    "#     PrintMod('After fire 48, 192'),\n",
    "#     FireModule(64, 256),\n",
    "#     PrintMod('After fire 64, 256'),\n",
    "#     FireModule(64, 256),\n",
    "#     PrintMod('After fire 64, 256'),\n",
    "\n",
    "#     tf.keras.layers.Dropout(0.1),\n",
    "#     # tf.keras.layers.Conv1D(75, 1),\n",
    "#     tf.keras.layers.Conv1D(75, 1, strides=1),\n",
    "#     PrintMod('After final layer'),\n",
    "#     # # tf.keras.layers.ReLU()\n",
    "\n",
    "#     tf.keras.layers.AvgPool1D(),\n",
    "#     PrintMod('avgpool1d'),\n",
    "\n",
    "#     tf.keras.layers.Conv1D(75, 3, strides=2,padding='same'),\n",
    "#     # tf.keras.layers.Conv1D(64, 3, strides=2, padding='same'), #output is 12 by 250\n",
    "#     PrintMod('After Conv1D'),\n",
    "\n",
    "#     tf.keras.layers.Conv1D(75, 3, strides=2,padding='same'),\n",
    "#     # tf.keras.layers.Conv1D(64, 3, strides=2, padding='same'), #output is 12 by 250\n",
    "#     PrintMod('After Conv1D'),\n",
    "\n",
    "#     tf.keras.layers.Conv1D(75, 3, strides=2,padding='same'),\n",
    "#     # tf.keras.layers.Conv1D(64, 3, strides=2, padding='same'), #output is 12 by 250\n",
    "#     PrintMod('After Conv1D'),\n",
    "\n",
    "#     tf.keras.layers.Conv1D(75, 3, strides=2,padding='same'),\n",
    "#     # tf.keras.layers.Conv1D(64, 3, strides=2, padding='same'), #output is 12 by 250\n",
    "#     tf.keras.layers.ReLU(),\n",
    "#     PrintMod('After Conv1D')\n",
    "\n",
    "    \n",
    "# ])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "samkernel",
   "language": "python",
   "name": "samsthing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
